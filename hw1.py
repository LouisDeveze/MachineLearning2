#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sat Oct  3 19:01:36 2020@author: kutlutoren"""import osimport numpy as npfrom collections import Counter#Static variables to change easier to adjustmax_word_number =2500training_ratio =0.75#This function will get all messages and create a dictionary for all the words in itdef create_Word_Dictionary(all_messages):        words_array = [] #define an empty array to store the words        #Check each line in the messages for words. "ham", "spam" and non alphanumeric values are not stored    for line in all_messages:         for word in line.split():                       #if word !="ham" and word !="spam" and word.isalpha():            if word !="ham" and word !="spam" and len(word)>1 and word.isalpha():                words_array.append(word)        #Get the most common element of the messages and store their number of usage.     word_dictionary = Counter(words_array).most_common()        if len(word_dictionary)>max_word_number:        return word_dictionary[0:max_word_number]        else:        return word_dictionary   ## Finish of Function for creating the dictionary. ## For the test whole messages.txt file number of unique words in messages is 7463.def create_word_matrix(all_messages,word_dictionary):        features = np.zeros((len(all_messages), len(word_dictionary)))    index1=0    for line in all_messages:        index2=0                for word,count in word_dictionary:                        if line.find(word)!=-1:                features[index1,index2]=1                        index2 += 1          index1 += 1            return features#Creates a bit vector to determine the type of the mesage. 1 if spam 0 if hamdef create_type_matrix(all_messages):    type_of_message=np.zeros(len(all_messages))        index1=0    for line in all_messages :        words = line.split()        if words[0] == "spam":            type_of_message[index1]=1        index1 +=1         return type_of_message#Assign Probabilities for words in spam messages. def spam_word_probabilities(dictionary, features, type_of_message):        spam_word_probabilities = np.zeros(len(dictionary))        spam_counter = 0        for row in range(0, len(type_of_message)):        if type_of_message[row] == 1:            spam_counter += 1            # Add each word prob the features (1 if contained, 0 if not)            for col in range(0, len(dictionary)):                spam_word_probabilities[col] += features[row, col]    # Divide the occurences by the amount of spam    for col in range(0, len(dictionary)):          spam_word_probabilities[col] /= spam_counter        print("Given messages have ", spam_counter, " SPAMs")    return spam_word_probabilities#Assign Probabilities for words in ham messages. def ham_word_probabilities(dictionary, features, type_of_message):        ham_word_probabilities = np.zeros(len(dictionary))        ham_counter = 0        for row in range(0, len(type_of_message)):        if type_of_message[row] == 0:            ham_counter += 1            # Add each word prob the features (1 if contained, 0 if not)            for col in range(0, len(dictionary)):                ham_word_probabilities[col] += features[row, col]    # Divide the occurences by the amount of spam    for col in range(0, len(dictionary)):          ham_word_probabilities[col] /= ham_counter        print("Given messages have ", ham_counter, " HAMs")    return ham_word_probabilities#Assaing the probabilities of the wordsdef train_word_prob(dictionary,type_of_word, features):       word_prob = np.zeros(len(dictionary))        for row in range(0, len(type_of_word)):        # Add each word prob the features (1 if contained, 0 if not)        for col in range(0, len(dictionary)):                word_prob[col] += features[row, col]       for col in range(0, len(dictionary)):          word_prob[col] /= len(type_of_word)    return word_prob#Creates and prints the confusion matrixdef confusion_matrix(predicted, current):    amount = len(predicted)    true_positive = 0.0    true_negative = 0.0    false_positive = 0.0    false_negative = 0.0    for i in range(0, amount):        if predicted[i] == current[i] and predicted[i] == 1:            true_positive += 1        elif predicted[i] == current[i] and predicted[i] == 0:            true_negative += 1        elif predicted[i] != current[i] and predicted[i] == 1:            false_positive += 1        elif predicted[i] != current[i] and predicted[i] == 0:            false_negative += 1    true_positive = true_positive / amount * 100    true_negative = true_negative / amount * 100    false_positive = false_positive / amount * 100    false_negative = false_negative / amount * 100    accuracy = true_positive + true_negative        print("Set with a size of ", len(predicted))    print("Global accuracy ", accuracy , "%")    print("True positive ", true_positive, "%")    print("True negative ", true_negative, "%")    print("False positive ", false_positive, "%")    print("False negative ", false_negative, "%\n")## Compute a vector of predicted output for the given input messagesdef predict(spam_model, ham_model, word_model, dictionary, messages):    # Create an array containing the messages output    output = np.zeros(len(messages))    spam_proba = np.zeros(len(dictionary))    ham_proba = np.zeros(len(dictionary))    # create the Test features matrix    features = create_word_matrix(messages, dictionary)    # For each Message    for row in range(0, len(messages)):        for col in range(0, len(dictionary)):                if features[row, col] == 1:                # Computing P(ϕn|Y=1)*P(ϕY)                spam_proba[col] = spam_model[col] * word_model[col]                # Computing P(ϕn|Y=0)*P(ϕY)                ham_proba[col] = ham_model[col] * word_model[col]            else:                spam_proba[col] = 0                ham_proba[col] = 0                # Now that spam proba and ham_proba are computed calculate output prediction        spam = spam_proba.sum()        ham = ham_proba.sum()        if spam > ham:            output[row] = 1        else:            output[row] = 0    return output# Main Function#Open the file and get the contentwith open("messages.txt", "r") as f:    all_lines = f.readlines()f.close()#Determine the size of training and test sizetraining_data_size = (int(len(all_lines)*training_ratio))testing_data_size = len(all_lines)-training_data_size#Divide the file according to the predefined training ratiotraining_lines = all_lines[0:training_data_size-1]testing_lines = all_lines[(training_data_size):len(all_lines)]print("Training set size is: {} Testing set size: {}".format(training_data_size,testing_data_size))# Create the dictionary for the training setword_dictionary = create_Word_Dictionary(training_lines)#print(len(word_dictionary))# Create features for that setfeatures = create_word_matrix(training_lines,word_dictionary)#print(features)# This holds the labes of the messages as a vectortraining_type_of_message = create_type_matrix(training_lines)spam_word_model = spam_word_probabilities(word_dictionary, features, training_type_of_message)ham_word_model = ham_word_probabilities(word_dictionary, features, training_type_of_message)word_model = train_word_prob(word_dictionary, training_type_of_message, features) #Creates the labes for the testing settesting_type_of_message = create_type_matrix(testing_lines)# test_predicted = predict(spam_word_model, ham_word_model, word_model, word_dictionary, testing_lines)print("\nConfusion Matrix for Test set with {} samples".format(testing_data_size))# Output confusion matrix for testing setconfusion_matrix(test_predicted, testing_type_of_message)train_predicted = predict(spam_word_model, ham_word_model, word_model, word_dictionary, training_lines)# Output confusion matrix for training setprint("\nConfusion Matrix for Training set with {} samples".format(training_data_size))confusion_matrix(train_predicted, training_type_of_message)